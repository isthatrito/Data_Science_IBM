{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isthatrito/isthatrito/blob/main/FinalAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "trusted": true,
        "id": "HBiGgWVVFtoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import piplite\n",
        "await piplite.install(['pandas'])\n",
        "await piplite.install(['numpy'])\n",
        "await piplite.install(['tabulate'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "kdT3JMUHFtop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import sklearn.metrics as metrics"
      ],
      "metadata": {
        "trusted": true,
        "id": "DpkEcCvBFtop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Dataset\n"
      ],
      "metadata": {
        "id": "QET1LcnJFtop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())"
      ],
      "metadata": {
        "trusted": true,
        "id": "eIiKeLc0Ftop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'"
      ],
      "metadata": {
        "trusted": true,
        "id": "ET8Oew6VFtoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await download(path, \"Weather_Data.csv\")\n",
        "filename =\"Weather_Data.csv\""
      ],
      "metadata": {
        "trusted": true,
        "id": "gAE-hUAaFtoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Weather_Data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "k7Yq_i1yFtoq",
        "outputId": "adf2da18-4954-4847-b68e-e59a79c4bde2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n\n   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n0             41          S        SSW  ...           92           84   \n1             41          W          E  ...           83           73   \n2             41        ESE        ESE  ...           88           86   \n3             41        NNE          E  ...           83           90   \n4             41        NNE          W  ...           88           74   \n\n   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n\n   RainTomorrow  \n0           Yes  \n1           Yes  \n2           Yes  \n3           Yes  \n4           Yes  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/1/2008</td>\n      <td>19.5</td>\n      <td>22.4</td>\n      <td>15.6</td>\n      <td>6.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>S</td>\n      <td>SSW</td>\n      <td>...</td>\n      <td>92</td>\n      <td>84</td>\n      <td>1017.6</td>\n      <td>1017.4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>20.7</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/2/2008</td>\n      <td>19.5</td>\n      <td>25.6</td>\n      <td>6.0</td>\n      <td>3.4</td>\n      <td>2.7</td>\n      <td>W</td>\n      <td>41</td>\n      <td>W</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>73</td>\n      <td>1017.9</td>\n      <td>1016.4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>22.4</td>\n      <td>24.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/3/2008</td>\n      <td>21.6</td>\n      <td>24.5</td>\n      <td>6.6</td>\n      <td>2.4</td>\n      <td>0.1</td>\n      <td>W</td>\n      <td>41</td>\n      <td>ESE</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>88</td>\n      <td>86</td>\n      <td>1016.7</td>\n      <td>1015.6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>23.5</td>\n      <td>23.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/4/2008</td>\n      <td>20.2</td>\n      <td>22.8</td>\n      <td>18.8</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>90</td>\n      <td>1014.2</td>\n      <td>1011.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>21.4</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/5/2008</td>\n      <td>19.7</td>\n      <td>25.7</td>\n      <td>77.4</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>88</td>\n      <td>74</td>\n      <td>1008.3</td>\n      <td>1004.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n"
      ],
      "metadata": {
        "id": "7-hlrD-RFtor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One Hot Encoding\n"
      ],
      "metadata": {
        "id": "mcU22tm8Ftor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to perform one hot encoding to convert categorical variables to binary variables.\n"
      ],
      "metadata": {
        "id": "MLxkGTlaFtor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "zh5xZhr7Ftor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"
      ],
      "metadata": {
        "id": "J3ENOBC2Ftor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lsvIB9LrFtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Data and Test Data\n"
      ],
      "metadata": {
        "id": "m555-FbNFtor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we set our 'features' or x values and our Y or target variable.\n"
      ],
      "metadata": {
        "id": "LSbL56f3Ftos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sydney_processed.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9721ub6_Ftos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sydney_processed = df_sydney_processed.astype(float)"
      ],
      "metadata": {
        "trusted": true,
        "id": "m35u78JAFtos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n",
        "Y = df_sydney_processed['RainTomorrow']"
      ],
      "metadata": {
        "trusted": true,
        "id": "x5d1PbReFtos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression\n"
      ],
      "metadata": {
        "id": "oZ2A4VmiFtos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"
      ],
      "metadata": {
        "id": "fTGsCO0iFtos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=10)\n",
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hw8HGJYjFtos",
        "outputId": "379132e2-3d98-4390-c8ab-94218f74932a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train set: (2616, 66) (2616,)\nTest set: (655, 66) (655,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"
      ],
      "metadata": {
        "id": "kkoWl5IbFtos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LinearReg = LinearRegression()\n",
        "x = np.asanyarray(x_train)\n",
        "y = np.asanyarray(y_train)\n",
        "LinearReg.fit(x_train, y_train)\n",
        "print ('Coefficients: ', LinearReg.coef_)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PKZnnZD3Ftot",
        "outputId": "9361f706-1fae-4ec3-88c1-7533d059083c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Coefficients:  [-2.36862502e-02  1.30060400e-02  7.29929096e-04  6.49363254e-03\n -3.51643494e-02  4.23733388e-03  1.82788340e-03  7.90075624e-04\n  9.56782146e-04  8.55986210e-03  7.69992241e-03 -9.24589847e-03\n -8.88017645e-03  1.00487910e-02  1.44675206e-02 -3.48703168e-03\n  8.47590247e+08  8.47590247e+08 -6.41324526e+09 -6.41324526e+09\n -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n -6.41324526e+09 -6.41324526e+09  1.43257002e+10  1.43257002e+10\n  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n  1.43257002e+10  1.43257002e+10 -1.09414185e+10 -1.09414185e+10\n -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n -1.09414185e+10 -1.09414185e+10]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ],
      "metadata": {
        "id": "Dx20MPfuFtot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = LinearReg.predict(x_test)\n",
        "x = np.asanyarray(x_test)\n",
        "y = np.asanyarray(y_test)\n",
        "print(\"Residual sum of squares: %.2f\"\n",
        "      % np.mean((predictions - y) ** 2))\n",
        "print('Variance score: %.2f' % LinearReg.score(x, y))"
      ],
      "metadata": {
        "trusted": true,
        "id": "zu9SqPD0Ftot",
        "outputId": "7308ffe7-c0d8-4ab6-c4e4-d459e7b62100"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Residual sum of squares: 0.12\nVariance score: 0.43\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ],
      "metadata": {
        "id": "LGM31wzaFtot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "LinearRegression_MAE = metrics.mean_absolute_error(predictions, y_test)\n",
        "LinearRegression_MSE = metrics.mean_squared_error(predictions, y_test)\n",
        "LinearRegression_R2 = metrics.r2_score(predictions, y_test)\n",
        "print(\"Mean absolute error: %.2f\" % LinearRegression_MAE)\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % LinearRegression_MSE)\n",
        "print(\"R2-score: %.2f\" % LinearRegression_R2 )"
      ],
      "metadata": {
        "trusted": true,
        "id": "z_GhT09bFtou",
        "outputId": "cd0e90aa-189a-424d-9a87-b64258f45562"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean absolute error: 0.26\nResidual sum of squares (MSE): 0.12\nR2-score: -0.38\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"
      ],
      "metadata": {
        "id": "M3MSfGIaFtou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dict = {'error_type':['LinearRegression_MAE','LinearRegression_MSE','LinearRegression_R2'],\n",
        "\n",
        "        'value':[LinearRegression_MAE,LinearRegression_MSE,LinearRegression_R2]}"
      ],
      "metadata": {
        "trusted": true,
        "id": "Klu_k0rYFtou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "Report =  pd.DataFrame(dict)\n",
        "print(tabulate(Report, headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "7SOQW8-QFtou",
        "outputId": "07e38e37-6b77-4d86-e67d-230e772b218c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "+----+----------------------+-----------+\n|    | error_type           |     value |\n|----+----------------------+-----------|\n|  0 | LinearRegression_MAE |  0.256319 |\n|  1 | LinearRegression_MSE |  0.11572  |\n|  2 | LinearRegression_R2  | -0.384754 |\n+----+----------------------+-----------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN\n"
      ],
      "metadata": {
        "id": "MyDc2yPGFtou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"
      ],
      "metadata": {
        "id": "IG0lE7nGFtou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors=4)\n",
        "KNN.fit(x_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HRVgaZeNFtov",
        "outputId": "52980b29-aa06-4dbd-f667-95162a5e85c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsClassifier(n_neighbors=4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ],
      "metadata": {
        "id": "nZ0AjduGFtov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = KNN.predict(x_test)\n",
        "predictions[0:5]"
      ],
      "metadata": {
        "trusted": true,
        "id": "CsUQYZJFFtov",
        "outputId": "f912bac0-4fce-4938-aad6-e7fa7bcef8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 1., 0., 0.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ],
      "metadata": {
        "id": "HZEpDsV3Ftov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN_Accuracy_Score =  metrics.accuracy_score(y_test, predictions)\n",
        "KNN_JaccardIndex = metrics.jaccard_score(y_test, predictions)\n",
        "KNN_F1_Score = metrics.f1_score(y_test, predictions)\n",
        "KNN_Log_Loss = metrics.log_loss(y_test, predictions)\n",
        "print(\"KNN Accuracy Score: \",KNN_Accuracy_Score)\n",
        "print(\"KNN_JaccardIndex: \",KNN_JaccardIndex)\n",
        "print(\"KNN F1 score : \", KNN_F1_Score)\n",
        "print(\"KNN Log Loss : \", KNN_Log_Loss)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zoaH7PRLFtow",
        "outputId": "17f6744b-6455-4125-e1df-f8b648ccbd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "KNN Accuracy Score:  0.8183206106870229\nKNN_JaccardIndex:  0.4251207729468599\nKNN F1 score :  0.5966101694915255\nKNN Log Loss :  6.275011880511857\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree\n"
      ],
      "metadata": {
        "id": "JK778NR-Ftow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"
      ],
      "metadata": {
        "id": "TMdI9sOMFtow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
        "Tree.fit(x_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WGMbJaotFtow",
        "outputId": "ccc56ce4-a863-422a-b27f-2c39e9280573"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DecisionTreeClassifier(criterion='entropy', max_depth=4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ],
      "metadata": {
        "id": "lemN24DOFtox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = Tree.predict(x_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6hhdMYnuFtox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ],
      "metadata": {
        "id": "7f71eEZwFtox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tree_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\n",
        "Tree_JaccardIndex = metrics.jaccard_score(y_test, predictions)\n",
        "Tree_F1_Score = metrics.f1_score(y_test, predictions)\n",
        "Tree_Log_Loss = metrics.log_loss(y_test, predictions)\n",
        "print(\"Tree accur_acy score: \", Tree_Accuracy_Score)\n",
        "print(\"Tree JaccardIndex : \", Tree_JaccardIndex)\n",
        "print(\"Tree_F1_Score : \", Tree_F1_Score)\n",
        "print(\"Tree Log Loss : \", Tree_Log_Loss)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KuT-AivTFtox",
        "outputId": "d47a97c6-3f26-4327-97dc-6bf6c57e54c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Tree accur_acy score:  0.8183206106870229\nTree JaccardIndex :  0.48034934497816595\nTree_F1_Score :  0.6489675516224188\nTree Log Loss :  6.275038737219435\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n"
      ],
      "metadata": {
        "id": "KOlsEgwxFtox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"
      ],
      "metadata": {
        "id": "mAY4btFUFtoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test =  train_test_split(features, Y, test_size = 0.2, random_state =1)\n",
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "U0aQnq8rFtoy",
        "outputId": "4adf43f1-5175-4d2a-ea0b-c02650b2754d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train set: (2616, 66) (2616,)\nTest set: (655, 66) (655,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"
      ],
      "metadata": {
        "id": "ZlFubTmTFtoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression(C=0.01, solver='liblinear').fit(x_train,y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bVFlZhA7Ftoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n"
      ],
      "metadata": {
        "id": "SXVJSHmyFtoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = LR.predict(x_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OrLSUrahFtoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_proba = LR.predict_proba(x_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rPypY1VJFto2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ],
      "metadata": {
        "id": "FUmqKECqFto3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR_Accuracy_Score = metrics.accuracy_score(y_test,predictions)\n",
        "LR_JaccardIndex = metrics.jaccard_score(y_test,predictions)\n",
        "LR_F1_Score = metrics.f1_score(y_test,predictions)\n",
        "LR_Log_Loss = metrics.log_loss(y_test, predictions)\n",
        "print(\"LR accuracy score: \", LR_Accuracy_Score)\n",
        "print(\"LR JaccardIndex : \", LR_JaccardIndex)\n",
        "print(\"LR F1 Score : \", LR_F1_Score)\n",
        "print(\"LR Log Loss : \", LR_Log_Loss)"
      ],
      "metadata": {
        "trusted": true,
        "id": "uZAffrezFto3",
        "outputId": "5eea9913-3327-4277-f724-bdaac9b909f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "LR accuracy score:  0.8274809160305343\nLR JaccardIndex :  0.4840182648401826\nLR F1 Score :  0.6523076923076923\nLR Log Loss :  5.958643233175305\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM\n"
      ],
      "metadata": {
        "id": "ouIALlfeFto3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"
      ],
      "metadata": {
        "id": "fo5m41swFto3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVM = svm.SVC(kernel='linear')\n",
        "SVM.fit(x_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "o1oc5fYNFto3",
        "outputId": "50fd59b2-4997-4192-fc68-5628eb214fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC(kernel='linear')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ],
      "metadata": {
        "id": "FvhupjlVFto4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = SVM.predict(x_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GHYhJr73Fto4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ],
      "metadata": {
        "id": "Zmj6RsqsFto4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVM_Accuracy_Score =  metrics.accuracy_score(y_test, predictions)\n",
        "SVM_JaccardIndex = metrics.jaccard_score(y_test, predictions)\n",
        "SVM_F1_Score =  metrics.f1_score(y_test, predictions)\n",
        "SVM_Log_Loss = metrics.log_loss(y_test, predictions)\n",
        "print(\"SVM accuracy score : \", SVM_Accuracy_Score)\n",
        "print(\"SVM jaccardIndex : \", SVM_JaccardIndex)\n",
        "print(\"SVM F1_score : \", SVM_F1_Score)\n",
        "print(\"SVM Log Loss : \", SVM_Log_Loss)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Am78CfAKFto4",
        "outputId": "50c7d76e-0291-4baa-d655-c31249caebbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM accuracy score :  0.833587786259542\nSVM jaccardIndex :  0.49537037037037035\nSVM F1_score :  0.6625386996904025\nSVM Log Loss :  5.747715745584566\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report\n"
      ],
      "metadata": {
        "id": "arvumE4XFto4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n",
        "\n",
        "\\*LogLoss is only for Logistic Regression Model\n"
      ],
      "metadata": {
        "id": "CWT7BI6lFto5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'KNN':[KNN_Accuracy_Score,KNN_JaccardIndex,KNN_F1_Score,KNN_Log_Loss],\n",
        "     'Tree':[Tree_Accuracy_Score, Tree_JaccardIndex, Tree_F1_Score, Tree_Log_Loss],\n",
        "     'LR':[LR_Accuracy_Score, LR_JaccardIndex, LR_F1_Score,LR_Log_Loss],\n",
        "     'SVM':[SVM_Accuracy_Score, SVM_JaccardIndex, SVM_F1_Score, SVM_Log_Loss]}\n",
        "Report = pd.DataFrame(data=d, index = ['Accuracy','Jaccard Index','F1-Score', 'LogLoss'])\n",
        "print(tabulate(Report, headers = 'keys', tablefmt = 'psql'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "beV86vAbFto5",
        "outputId": "dc2e41e7-a47d-4a3a-efa6-335c26c6cfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "+---------------+----------+----------+----------+----------+\n|               |      KNN |     Tree |       LR |      SVM |\n|---------------+----------+----------+----------+----------|\n| Accuracy      | 0.818321 | 0.818321 | 0.827481 | 0.833588 |\n| Jaccard Index | 0.425121 | 0.480349 | 0.484018 | 0.49537  |\n| F1-Score      | 0.59661  | 0.648968 | 0.652308 | 0.662539 |\n| LogLoss       | 6.27501  | 6.27504  | 5.95864  | 5.74772  |\n+---------------+----------+----------+----------+----------+\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}